{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaforge.models.metadataentry import MetadataEntry\n",
    "from metaforge.models.metadatamodel import MetadataModel\n",
    "from metaforge.parsers.ang_parser import AngParser\n",
    "\n",
    "import metaforge.utilities.ht_utilities\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import hyperthought as ht"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Existing MetaForge Template ##\n",
    "\n",
    "We are going to use an existing EBSD 2 Phase template located in the \"example_templates\" folder and load that into memory using the \"from_json_file()\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set teh path of the file to store the JSON of the model\n",
    "ez_file_path = 'example_templates/MultiPhase.ez'\n",
    "\n",
    "# Read the MetadataModel from the json file\n",
    "model = MetadataModel.from_json_file(ez_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an ANG Dictionary from an existing Data file ##\n",
    "\n",
    "We now want to load a data file whose values will be extracted and used as the meta data that gets uploaded and tagged onto the uploaded data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path of the data file to use to build the MetadataModel\n",
    "data_prefix = '/Users/Shared/DREAM3D_SDK/'\n",
    "data_file_path = Path(f'{data_prefix}/DREAM3D_Data/Data/SmallIN100/Slice_1.ang')\n",
    "\n",
    "# Convert the ANG file into a dictionary\n",
    "ang_parser = AngParser()\n",
    "ang_dict = ang_parser.parse_header(data_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we might want to sync the template with the actual ANG data that just got read from the .ang file. This can be important if you want to error out because template values were defined in the template but are *not* available in the actual data file. This can happen for instance if the template extracts data from multiple phases but the data file only has a single phase. In this code we simply print what is missing but proceed on. In real life you would probably want to error check or return early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync the the MetadataModel from the ANG header dictionary\n",
    "missing_entries: List[MetadataEntry] = model.update_model_values_from_dict(ang_dict)\n",
    "if len(missing_entries) != 0:\n",
    "  print('Not all values that appear in the Template file were in the input data file.')\n",
    "  for e in missing_entries:\n",
    "    print(f'{e.source_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with HyperThought ##\n",
    "\n",
    "Now that we have setup our in memory template and verified our model is correct, we need to authenticate to HyperThought. We do this by creating an **auth_control** variable through the use of the *htauthcontroller* class.\n",
    "\n",
    "**NOTE TO THE USER**\n",
    "The access key used here is stale. You will need to go get a new Access Key from your HyperThought website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the template to upload to HyperThought\n",
    "# Set your API Access Key which you would get from HyperThought Web site\n",
    "accessKey = 'eyJhY2Nlc3NUb2tlbiI6ICI0M2YyMDdiYjVkY2Y0MGMxOGNiNWQ3YjE5NTdmMGE4MiIsICJyZWZyZXNoVG9rZW4iOiAiZGYwMmFlNGU4OTUwNDhmZWJjNTVkYTU3YjJmMTA0YTkiLCAiZXhwaXJlc0luIjogMjg2NiwgImV4cGlyZXNBdCI6ICIyMDIyLTA2LTMwVDExOjQ3OjU0LTA0OjAwIiwgImJhc2VVcmwiOiAiaHR0cHM6Ly9odC5ibHVlcXVhcnR6Lm5ldCIsICJjbGllbnRJZCI6ICIwODc3NjAiLCAiY2xpZW50U2VjcmV0IjogIjJjMzJhYmYyMDBlZGE3MTkxNDQxM2YyYTEwNTE5YmI0YzAzMWZmYjgxOTYwNDQ5OTVlODgxOWVjIn0='\n",
    "\n",
    "# Create an ht.auth.Authorization to hold the API key, and create WorkspacesAPI and FilesAPI objects\n",
    "auth_control = ht.auth.Authorization(accessKey, verify=False)\n",
    "workspaces_api = ht.api.workspaces.WorkspacesAPI(auth_control)\n",
    "files_api = ht.api.files.FilesAPI(auth_control)\n",
    "\n",
    "# Upload to a folder created at the root level.\n",
    "path = \",\"\n",
    "\n",
    "# Set the remote directory to create. This DOES NOT check if that folder already exists\n",
    "remoteDirPath = \"Unit_Test\"\n",
    "\n",
    "\n",
    "# Get a list of the projects that the user has access to.\n",
    "workspaces_list = workspaces_api.get_workspaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the workspace names {Optional}\n",
    "for workspace in workspaces_list:\n",
    "    print(f'{workspace[\"name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for a specific workspace by *Workspace Title*\n",
    "workspace_title = 'Project X-Caliber'\n",
    "workspace_exists = False\n",
    "workspace_json = {}\n",
    "workspace_id = \"\"\n",
    "for workspace in workspaces_list:\n",
    "    if workspace[\"name\"] == workspace_title:\n",
    "        workspace_exists = True\n",
    "        workspace_json = workspace\n",
    "        workspace_id = workspace_json[\"id\"]\n",
    "\n",
    "# Check to make sure we found the Project. In REAL LIFE you would probably error out at this point if the\n",
    "# project was not found.\n",
    "if workspace_exists == False:\n",
    "    print(f'The requested workspace \"{workspace_title}\" does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file/folder list from the project listed in the previous code\n",
    "workspace_folder_list = files_api.get_from_location(space_id=workspace_id,\n",
    "                                                    path=',',\n",
    "                                                    file_type=ht.api.files.FilesAPI.FileType.FILES_AND_FOLDERS)\n",
    "\n",
    "# Print the list of folders/files inside the project of interest [Optional]\n",
    "for wf in workspace_folder_list:\n",
    "    print(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the remote directory to create.\n",
    "remote_exists = False\n",
    "remote_folder_name = \"Unit_Test\"\n",
    "remote_folder_uuid = \"\"\n",
    "print(\"Checking if remote folder {remote_folder_name} exists\")\n",
    "for f in workspace_folder_list:\n",
    "    print(f)\n",
    "    if f[\"name\"] == remote_folder_name:\n",
    "        remote_exists = True\n",
    "        remote_folder_uuid = f[\"pk\"]\n",
    "        print(f'name: {f[\"name\"]}  UUID: {remote_folder_uuid}')\n",
    "  \n",
    "if not remote_exists:\n",
    "    print(\"Remote Folder does not exist.. creating remote folder {remote_folder_name}\")\n",
    "    remote_folder_uuid = files_api.create_folder(name = remote_folder_name,\n",
    "                                        space_id = workspace_id,\n",
    "                                        path = ',',\n",
    "                                        metadata = None)\n",
    "\n",
    "    # Get the file/folder list from the project listed in the previous code [Optional]\n",
    "    # This part is optional but probably necessary in real life to sanity check that the\n",
    "    # requested directory was created.\n",
    "    workspace_folder_list = files_api.get_from_location(space_id=workspace_id,\n",
    "                                                        path=',',\n",
    "                                                        file_type=ht.api.files.FilesAPI.FileType.FILES_AND_FOLDERS)\n",
    "\n",
    "    # Print the list of folders/files inside the project of interest [Optional]\n",
    "    for wf in workspace_folder_list:\n",
    "        print(wf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading Data Files with MetaData ##\n",
    "\n",
    "We are going to upload a data file with Meta-Data extracted from a given Data file using a give template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Meta-Data from the Template/Model\n",
    "missing_entries = []\n",
    "metadata = ht_utilities.ezmodel_to_ht_metadata(model=model, missing_entries=missing_entries, metadata_file_chosen=True)\n",
    "\n",
    "# Pick your data files to upload\n",
    "filelist = f'{data_prefix}DREAM3D_Data/Data/SmallIN100/Slice_1.ang'\n",
    "\n",
    "# Perform the upload.\n",
    "remote_folder_id_path = files_api.get_id_path(space_id=workspace_id,\n",
    "                                              path='/' + remote_folder_name)\n",
    "\n",
    "file_id, file_name = files_api.upload(local_path=filelist,\n",
    "                                      space_id=workspace_id,\n",
    "                                      path=remote_folder_id_path,\n",
    "                                      metadata=metadata)\n",
    "print(f'{file_name}: {file_id}')\n",
    "print(\"Upload completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaforge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12b51ec3434dceed89fed924fa8f2c194bb59f2160564b5d4e572711e0a340d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
